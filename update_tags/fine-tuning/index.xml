<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Fine-Tuning on Sujith Quintelier</title><link>https://quintelier.dev/update_tags/fine-tuning/</link><description>Recent content in Fine-Tuning on Sujith Quintelier</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Thu, 19 Feb 2026 01:01:09 +0000</lastBuildDate><atom:link href="https://quintelier.dev/update_tags/fine-tuning/index.xml" rel="self" type="application/rss+xml"/><item><title>ai: What’s new in Microsoft Foundry | Dec 2025 &amp; Jan 2026</title><link>https://quintelier.dev/updates/what-s-new-in-microsoft-foundry-dec-2025-jan-2026/</link><pubDate>Thu, 19 Feb 2026 01:01:09 +0000</pubDate><guid>https://quintelier.dev/updates/what-s-new-in-microsoft-foundry-dec-2025-jan-2026/</guid><description>&lt;p>Microsoft Foundry’s Dec 2025–Jan 2026 updates add several new foundation models, expand audio and fine-tuning capabilities, and introduce SDK changes including an azure-ai-projects v2 beta consolidation.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Source:&lt;/strong> &lt;a href="https://devblogs.microsoft.com/foundry/whats-new-in-microsoft-foundry-dec-2025-jan-2026/" target="_blank" rel="noopener noreferrer">Microsoft AI Foundry Blog&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>ai: DPO Fine-Tuning Using Microsoft Foundry SDK</title><link>https://quintelier.dev/updates/dpo-fine-tuning-using-microsoft-foundry-sdk/</link><pubDate>Fri, 13 Feb 2026 23:13:44 +0000</pubDate><guid>https://quintelier.dev/updates/dpo-fine-tuning-using-microsoft-foundry-sdk/</guid><description>&lt;p>Microsoft Foundry published a guide on using the Foundry SDK to fine-tune LLMs with Direct Preference Optimization (DPO) to better align outputs with human preferences.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Source:&lt;/strong> &lt;a href="https://devblogs.microsoft.com/foundry/dpo-fine-tuning-using-microsoft-foundry-sdk/" target="_blank" rel="noopener noreferrer">Microsoft AI Foundry Blog&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>ai: Beyond the Prompt – Why and How to Fine-tune Your Own Models</title><link>https://quintelier.dev/updates/beyond-the-prompt-why-and-how-to-fine-tune-your-own-models/</link><pubDate>Wed, 11 Feb 2026 17:29:15 +0000</pubDate><guid>https://quintelier.dev/updates/beyond-the-prompt-why-and-how-to-fine-tune-your-own-models/</guid><description>&lt;p>Microsoft Foundry argues that enterprise LLM deployments often need behavior-level alignment (consistency, reliability, policy compliance) that prompt engineering and RAG cannot provide, positioning fine-tuning as the mechanism to change model behavior.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Source:&lt;/strong> &lt;a href="https://devblogs.microsoft.com/foundry/beyond-the-prompt-why-and-how-to-fine-tune-your-own-models/" target="_blank" rel="noopener noreferrer">Microsoft AI Foundry Blog&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>azure: [In preview] Announcing: Developer Training tier for low-cost fine-tuning training</title><link>https://quintelier.dev/updates/in-preview-announcing-developer-training-tier-for-low-cost-fine-tuning-training/</link><pubDate>Tue, 18 Nov 2025 16:00:16 +0000</pubDate><guid>https://quintelier.dev/updates/in-preview-announcing-developer-training-tier-for-low-cost-fine-tuning-training/</guid><description>&lt;p>Microsoft Foundry announced a Developer Training tier (preview) that offers ultra-low-cost fine-tuning model training by using spot capacity. The tier aims to provide training affordability comparable to the existing Developer hosting tier, specifically for the training phase of fine-tuning workflows.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Source:&lt;/strong> &lt;a href="https://azure.microsoft.com/updates?id=525952" target="_blank" rel="noopener noreferrer">Azure Updates&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>azure: [In preview] Public Preview: Microsoft Foundry Fine-Tuning Updates</title><link>https://quintelier.dev/updates/in-preview-public-preview-microsoft-foundry-fine-tuning-updates/</link><pubDate>Tue, 18 Nov 2025 16:00:16 +0000</pubDate><guid>https://quintelier.dev/updates/in-preview-public-preview-microsoft-foundry-fine-tuning-updates/</guid><description>&lt;p>Microsoft Foundry Fine-Tuning enters Public Preview with a complete UI redesign that emphasizes an agent-first experience. The updated interface streamlines model creation, evaluation, and deployment workflows and adds integration with Visual Studio to improve developer and data scientist productivity.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Source:&lt;/strong> &lt;a href="https://azure.microsoft.com/updates?id=526742" target="_blank" rel="noopener noreferrer">Azure Updates&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>ai: A Developer’s Guide to Fine-Tuning GPT-4o for Image Classification on Azure AI Foundry</title><link>https://quintelier.dev/updates/a-developer-s-guide-to-fine-tuning-gpt-4o-for-image-classification-on-azure-ai-foundry/</link><pubDate>Mon, 20 Oct 2025 07:11:50 +0000</pubDate><guid>https://quintelier.dev/updates/a-developer-s-guide-to-fine-tuning-gpt-4o-for-image-classification-on-azure-ai-foundry/</guid><description>&lt;p>This guide demonstrates how to quickly improve image classification accuracy by fine-tuning GPT-4o (a vision-language model) on Azure OpenAI via Azure AI Foundry. It targets ML practitioners, app developers, and curious users, and emphasizes that boosting performance can be done without deep learning expertise through a step-by-step walkthrough.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Source:&lt;/strong> &lt;a href="https://devblogs.microsoft.com/foundry/a-developers-guide-to-fine-tuning-gpt-4o-for-image-classification-on-azure-ai-foundry/" target="_blank" rel="noopener noreferrer">Microsoft AI Foundry Blog&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>ai: The Developer’s Guide to Smarter Fine-tuning: Unlock custom AI for every business challenge</title><link>https://quintelier.dev/updates/the-developer-s-guide-to-smarter-fine-tuning-unlock-custom-ai-for-every-business-challenge/</link><pubDate>Tue, 14 Oct 2025 19:01:20 +0000</pubDate><guid>https://quintelier.dev/updates/the-developer-s-guide-to-smarter-fine-tuning-unlock-custom-ai-for-every-business-challenge/</guid><description>&lt;p>Azure AI Foundry provides a streamlined platform for smarter, faster, and more accessible fine-tuning so developers can customize models for practical business problems — from reasoning agents to adaptive tools and scalable workflows — accompanied by best practices, hands-on resources, and recent innovations to accelerate development, testing, and deployment.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Source:&lt;/strong> &lt;a href="https://devblogs.microsoft.com/foundry/the-developers-guide-to-smarter-fine-tuning/" target="_blank" rel="noopener noreferrer">Microsoft AI Foundry Blog&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>azure: [Launched] Generally Available: AI toolchain operator add-on (KAITO) for AKS</title><link>https://quintelier.dev/updates/launched-generally-available-ai-toolchain-operator-add-on-kaito-for-aks/</link><pubDate>Tue, 07 Oct 2025 12:00:49 +0000</pubDate><guid>https://quintelier.dev/updates/launched-generally-available-ai-toolchain-operator-add-on-kaito-for-aks/</guid><description>&lt;p>Microsoft announced general availability of the AI toolchain operator add-on (KAITO) for Azure Kubernetes Service (AKS). KAITO streamlines deployment of AI inference and fine-tuning workflows using popular open-source frameworks, with vLLM set as the default inference engine to simplify management and scaling of model serving.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Source:&lt;/strong> &lt;a href="https://azure.microsoft.com/updates?id=503263" target="_blank" rel="noopener noreferrer">Azure Updates&lt;/a>&lt;/li>
&lt;/ul></description></item></channel></rss>