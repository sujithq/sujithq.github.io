<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Behavioral-Alignment on Sujith Quintelier</title><link>https://quintelier.dev/update_tags/behavioral-alignment/</link><description>Recent content in Behavioral-Alignment on Sujith Quintelier</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Wed, 11 Feb 2026 17:29:15 +0000</lastBuildDate><atom:link href="https://quintelier.dev/update_tags/behavioral-alignment/index.xml" rel="self" type="application/rss+xml"/><item><title>ai: Beyond the Prompt â€“ Why and How to Fine-tune Your Own Models</title><link>https://quintelier.dev/updates/beyond-the-prompt-why-and-how-to-fine-tune-your-own-models/</link><pubDate>Wed, 11 Feb 2026 17:29:15 +0000</pubDate><guid>https://quintelier.dev/updates/beyond-the-prompt-why-and-how-to-fine-tune-your-own-models/</guid><description>&lt;p>Microsoft Foundry argues that enterprise LLM deployments often need behavior-level alignment (consistency, reliability, policy compliance) that prompt engineering and RAG cannot provide, positioning fine-tuning as the mechanism to change model behavior.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Source:&lt;/strong> &lt;a href="https://devblogs.microsoft.com/foundry/beyond-the-prompt-why-and-how-to-fine-tune-your-own-models/" target="_blank" rel="noopener noreferrer">Microsoft AI Foundry Blog&lt;/a>&lt;/li>
&lt;/ul></description></item></channel></rss>