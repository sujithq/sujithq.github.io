<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Inference on Sujith Quintelier</title><link>https://quintelier.dev/update_tags/inference/</link><description>Recent content in Inference on Sujith Quintelier</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Thu, 20 Nov 2025 18:45:04 +0000</lastBuildDate><atom:link href="https://quintelier.dev/update_tags/inference/index.xml" rel="self" type="application/rss+xml"/><item><title>azure: [Launched] Generally Available: MCP support for AI toolchain operator add-on in AKS</title><link>https://quintelier.dev/updates/launched-generally-available-mcp-support-for-ai-toolchain-operator-add-on-in-aks/</link><pubDate>Thu, 20 Nov 2025 18:45:04 +0000</pubDate><guid>https://quintelier.dev/updates/launched-generally-available-mcp-support-for-ai-toolchain-operator-add-on-in-aks/</guid><description>&lt;p>Microsoft announced General Availability of MCP support for the AI Toolchain Operator add-on in AKS. The add-on now supports KAITO inference workspaces with integrated tool calling and Model Context Protocol (MCP), helping address challenges related to dynamic model/context handling in inference workflows.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Source:&lt;/strong> &lt;a href="https://azure.microsoft.com/updates?id=523152" target="_blank" rel="noopener noreferrer">Azure Updates&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>azure: [Launched] Generally Available: AI toolchain operator add-on (KAITO) for AKS</title><link>https://quintelier.dev/updates/launched-generally-available-ai-toolchain-operator-add-on-kaito-for-aks/</link><pubDate>Tue, 07 Oct 2025 12:00:49 +0000</pubDate><guid>https://quintelier.dev/updates/launched-generally-available-ai-toolchain-operator-add-on-kaito-for-aks/</guid><description>&lt;p>Microsoft announced general availability of the AI toolchain operator add-on (KAITO) for Azure Kubernetes Service (AKS). KAITO streamlines deployment of AI inference and fine-tuning workflows using popular open-source frameworks, with vLLM set as the default inference engine to simplify management and scaling of model serving.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Source:&lt;/strong> &lt;a href="https://azure.microsoft.com/updates?id=503263" target="_blank" rel="noopener noreferrer">Azure Updates&lt;/a>&lt;/li>
&lt;/ul></description></item></channel></rss>