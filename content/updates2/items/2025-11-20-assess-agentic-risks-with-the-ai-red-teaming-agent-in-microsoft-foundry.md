---
title: "ai: Assess Agentic Risks with the AI Red Teaming Agent in Microsoft Foundry"
date: 2025-11-20T16:00:05.000Z
slug: assess-agentic-risks-with-the-ai-red-teaming-agent-in-microsoft-foundry
update_categories: ["ai"]
update_tags: ["Microsoft Foundry", "AI red teaming", "agentic risk", "model safety", "security", "public preview", "AI governance"]
update_bullets: ["New capabilities in Microsoft Foundry target model- and agentic-pipeline safety and security assessments.", "AI Red Teaming Agent automates adversarial testing of models and agentic systems to surface vulnerabilities and unsafe behaviors.", "Designed to help organizations identify risks early and apply safeguards prior to production deployment.", "Integrates with existing Foundry workflows and tooling for red teaming and risk management.", "Available now in public preview for customers to evaluate and adopt."]
timeframes: ["2025-11"]
link: "https://devblogs.microsoft.com/foundry/assess-agentic-risks-with-the-ai-red-teaming-agent-in-microsoft-foundry/"
source: "Microsoft AI Foundry Blog"
timeframeKey: "2025-11"
id: "16FCFF838909B363B66A892E5751E62FA2E831ABC54EA0A2B88611B061163FF1"
contentHash: "40A14D47B6D1BA7968047FCB3734ADC989AADB271AB6EFFB1728CC3B72D4C980"
draft: false
type: "updates2"
llmSummary: "Microsoft Foundry now offers major public-preview enhancements for models and agentic AI pipelines, including an AI Red Teaming Agent that helps organizations proactively identify and mitigate safety and security risks in models and agentic systems before they enter production."
---

Microsoft Foundry now offers major public-preview enhancements for models and agentic AI pipelines, including an AI Red Teaming Agent that helps organizations proactively identify and mitigate safety and security risks in models and agentic systems before they enter production.

- **Source:** [Microsoft AI Foundry Blog](https://devblogs.microsoft.com/foundry/assess-agentic-risks-with-the-ai-red-teaming-agent-in-microsoft-foundry/)
